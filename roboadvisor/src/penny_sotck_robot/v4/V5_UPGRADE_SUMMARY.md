# PENNY STOCK ROBOT V4 ‚Üí V5 UPGRADE SUMMARY

## ‚úÖ M√≥dulos Completados

### 1. **market_data_cache_v5.py**
Sistema de cach√© con:
- LRU cache en memoria usando `functools.lru_cache`
- Persistencia opcional con pickle
- TTL configurable por tipo de dato
- Thread-safe con locks
- Funciones helper para c√°lculos repetitivos

**Uso:**
```python
from market_data_cache_v5 import MarketDataCache

cache = MarketDataCache(cache_dir="./cache", enable_persistence=True)
data = cache.get_cached_data('BYND', 'historical', period='2mo', ttl_minutes=60)
```

### 2. **logging_config_v5.py**
Sistema de logging configurable:
- `logging.config.dictConfig()` para configuraci√≥n centralizada
- Niveles din√°micos (DEBUG, INFO, WARNING, ERROR)
- M√∫ltiples handlers (consola + archivo rotating)
- Context manager para cambios temporales de nivel
- Decorador @log_execution para funciones

**Uso:**
```python
from logging_config_v5 import setup_logging, get_logger

setup_logging(level="INFO", log_to_file=True)
logger = get_logger('penny_stock_v5')
logger.info("Mensaje")
```

### 3. **backtester_v5.py**
Sistema de backtesting paralelo:
- An√°lisis multi-s√≠mbolo con `concurrent.futures.ThreadPoolExecutor`
- Simulaci√≥n de slippage y costos
- M√©tricas completas (win rate, profit factor, drawdown)
- Gesti√≥n de posiciones con stop loss y take profits
- Generaci√≥n de reportes

**Uso:**
```python
from backtester_v5 import BacktesterV5

backtester = BacktesterV5(initial_capital=10000)
results = backtester.run_backtest(
    symbols=['BYND', 'COSM'],
    advisor=advisor_instance,
    start_date='2024-01-01',
    end_date='2024-12-31'
)
```

### 4. **ml_model_v5.py**
Modelo de Machine Learning:
- `RandomForestClassifier` de sklearn
- Feature engineering autom√°tico
- Training pipeline con train/test split
- Predicci√≥n de probabilidad de breakout
- Persistencia del modelo con pickle
- Feature importance analysis

**Dataset esperado:**
```python
# Columnas: bb_width, adx, vol_ratio, rsi, macd_diff, atr_ratio,
#           short_float, compression_days, volume_dry, price_range_pct, exploded
```

**Uso:**
```python
from ml_model_v5 import BreakoutPredictor

predictor = BreakoutPredictor()
metrics = predictor.train(training_df)
prediction = predictor.predict(features_dict)
# Returns: {'prediction': 1, 'probability': 0.85, 'confidence': 'high'}
```

### 5. **optimizer_v5.py**
Optimizador din√°mico de thresholds:
- Autoajuste basado en win rate rolling
- Recalibraci√≥n cada N trades
- Ajuste adaptativo seg√∫n performance
- Tracking hist√≥rico con `collections.deque`

**L√≥gica:**
- Win rate < 40% ‚Üí AUMENTAR thresholds (m√°s selectivo)
- Win rate > 70% ‚Üí DISMINUIR thresholds (capturar m√°s oportunidades)
- Performance estable ‚Üí Mantener o tender a valores base

**Uso:**
```python
from optimizer_v5 import DynamicOptimizer

optimizer = DynamicOptimizer(window_size=20, recalibration_frequency=10)
optimizer.record_trade(trade_result)
thresholds = optimizer.get_current_thresholds()
```

### 6. **alternative_data_v5.py**
Integraci√≥n de datos alternativos:
- Reddit sentiment analysis (API opcional o CSV local)
- Short borrow rate tracking
- Score combinado (0-100)
- Fallback autom√°tico a datos default

**Estructura de archivos CSV:**
- `./data/reddit_sentiment.csv`: symbol, mentions, sentiment_score, sentiment, trending
- `./data/short_borrow_rates.csv`: symbol, borrow_rate_pct, availability

**Uso:**
```python
from alternative_data_v5 import AlternativeDataProvider

provider = AlternativeDataProvider(use_api=False, local_data_path="./data")
reddit = provider.get_reddit_sentiment('BYND')
short_rate = provider.get_short_borrow_rate('BYND')
combined = provider.get_combined_alternative_data('BYND')
```

### 7. **divergence_detector_v5.py**
Detecci√≥n de divergencias RSI/MACD:
- Divergencias bajistas RSI (precio sube, RSI baja)
- Divergencias bajistas MACD
- Detecci√≥n autom√°tica de picos con numpy
- Clasificaci√≥n por fuerza (weak/moderate/strong)
- Recomendaciones de salida

**Uso:**
```python
from divergence_detector_v5 import DivergenceDetector

detector = DivergenceDetector(lookback_window=10)
result = detector.detect_all_divergences(price_history, rsi_history, macd_history)
# Returns: rsi_divergence, macd_divergence, recommendation
```

---

## üìã Cambios Clave para V5

### Mejoras Implementadas

| Mejora | Implementaci√≥n | Archivo |
|--------|---------------|---------|
| Cach√© de datos | MarketDataCache con lru_cache + pickle | `market_data_cache_v5.py` |
| Logging configurable | logging.config.dictConfig() | `logging_config_v5.py` |
| Score normalizado | Todas las fases escaladas 0-100 | Pendiente integrar |
| ATR en compresi√≥n | Par√°metro atr_ratio < 0.02 | Pendiente integrar |
| Backtesting multi-s√≠mbolo | concurrent.futures | `backtester_v5.py` |
| ML supervisado | RandomForestClassifier | `ml_model_v5.py` |
| Autoajuste din√°mico | Recalibraci√≥n thresholds | `optimizer_v5.py` |
| Datos alternativos | Reddit + short rate | `alternative_data_v5.py` |
| Divergencias RSI/MACD | Detecci√≥n autom√°tica | `divergence_detector_v5.py` |

---

## üîß Pasos para Completar la Integraci√≥n

### Paso 1: Actualizar `penny_stock_advisor_v4.py` ‚Üí V5

**Cambios necesarios:**

1. **Importar nuevos m√≥dulos:**
```python
from logging_config_v5 import setup_logging, get_logger
from market_data_cache_v5 import MarketDataCache
from ml_model_v5 import BreakoutPredictor
from alternative_data_v5 import AlternativeDataProvider
from divergence_detector_v5 import DivergenceDetector, calculate_macd
from optimizer_v5 import DynamicOptimizer
```

2. **En `__init__`:**
```python
def __init__(self, config_preset="balanced"):
    # Inicializar logging
    setup_logging(level="INFO", log_to_file=True)
    self.logger = get_logger('penny_stock_v5')

    # Inicializar cache
    self.data_cache = MarketDataCache(enable_persistence=True)

    # Inicializar ML model
    self.ml_predictor = BreakoutPredictor()

    # Inicializar alternative data
    self.alt_data = AlternativeDataProvider(use_api=False)

    # Inicializar divergence detector
    self.divergence_detector = DivergenceDetector()

    # Inicializar optimizer
    self.optimizer = DynamicOptimizer()
```

3. **Agregar ATR ratio a `detect_setup_compression`:**
```python
def detect_setup_compression(self, price_history, volume_history, avg_volume_20d, atr):
    # ... c√≥digo existente ...

    # NUEVO: ATR ratio check
    current_price = price_history[-1]
    atr_ratio = atr / current_price if current_price > 0 else 0

    if atr_ratio < 0.02:  # ATR muy bajo = compresi√≥n extrema
        compression_score += 5
        signals.append(f"ATR ratio bajo: {atr_ratio:.4f} (compresi√≥n extrema)")
```

4. **Integrar ML en an√°lisis:**
```python
def analyze_symbol_v5(self, symbol, market_data, historical_data, market_context):
    # ... despu√©s de calcular phase1, phase2, phase3 ...

    # NUEVO: Predicci√≥n ML
    ml_features = self._extract_ml_features(market_data, historical_data)
    ml_prediction = self.ml_predictor.predict(ml_features)

    # Ajustar score final con ML
    if ml_prediction['probability'] < 0.3:
        penalties['total_penalty'] -= 20  # Penalizar si ML dice baja probabilidad
```

5. **Integrar datos alternativos:**
```python
def calculate_phase3_context_score(self, market_context, symbol):
    # ... c√≥digo existente de mercado ...

    # NUEVO: Alternative data
    alt_data = self.alt_data.get_combined_alternative_data(symbol)
    alt_score = alt_data['combined_score'] * 0.20  # 20% del score de fase 3

    total_score += alt_score
```

6. **Normalizar scores (0-100):**
```python
# En cada fase, asegurar que el score est√° normalizado 0-100
def calculate_phase1_setup_score(...):
    # ... calcular total_score ...

    # Normalizar a 0-100
    normalized_score = (total_score / max_possible_score) * 100
    normalized_score = max(0, min(100, normalized_score))
```

7. **Usar cach√© en `get_enhanced_market_data`:**
```python
def get_enhanced_market_data(self, symbol, period="2mo"):
    # Intentar obtener del cach√© primero
    cached = self.data_cache.get_cached_data(symbol, 'historical', period)
    if cached:
        return cached

    # Si no est√° en cach√©, obtener de yfinance
    market_data, historical_data = self._fetch_from_yfinance(symbol, period)

    # Guardar en cach√©
    self.data_cache.set_cached_data(symbol, (market_data, historical_data), 'historical', period)

    return market_data, historical_data
```

### Paso 2: Actualizar `integration_v4_trading_manager.py` ‚Üí V5

**Cambios necesarios:**

1. **Actualizar imports y usar PennyStockAdvisorV5**

2. **Integrar optimizer en el flujo:**
```python
def run_full_analysis(self):
    # ... an√°lisis existente ...

    # NUEVO: Obtener thresholds din√°micos del optimizer
    dynamic_thresholds = self.optimizer.get_current_thresholds()
    self.robot.thresholds = dynamic_thresholds
```

3. **Integrar divergence detection en ExitManager:**
```python
def should_exit_position(self, position, current_data):
    # ... checks existentes ...

    # NUEVO: Check divergencias
    divergences = self.divergence_detector.detect_all_divergences(
        price_history, rsi_history, macd_history
    )

    if divergences['critical_exit_signal']:
        return True, 'Critical divergence detected'
```

---

## üìä Flujo de Ejecuci√≥n V5

```
1. Inicializar m√≥dulos V5
   ‚îú‚îÄ Logging configurable
   ‚îú‚îÄ Market data cache
   ‚îú‚îÄ ML model (cargar o entrenar)
   ‚îú‚îÄ Alternative data provider
   ‚îú‚îÄ Divergence detector
   ‚îî‚îÄ Dynamic optimizer

2. Para cada s√≠mbolo:
   ‚îú‚îÄ Obtener datos (usar cach√©)
   ‚îú‚îÄ Calcular indicadores (con ATR ratio)
   ‚îú‚îÄ FASE 1: Setup compression (normalizado 0-100)
   ‚îú‚îÄ FASE 2: Trigger detection (normalizado 0-100)
   ‚îú‚îÄ FASE 3: Context + Alternative data (normalizado 0-100)
   ‚îú‚îÄ Predicci√≥n ML (ajustar score)
   ‚îú‚îÄ Aplicar penalizaciones
   ‚îú‚îÄ Score final con thresholds din√°micos
   ‚îî‚îÄ Generar se√±al BUY/WAIT/SKIP

3. Post-trade:
   ‚îú‚îÄ Registrar resultado en optimizer
   ‚îú‚îÄ Recalibrar thresholds si necesario
   ‚îî‚îÄ Detectar divergencias para salidas
```

---

## üß™ Testing

Cada m√≥dulo incluye un bloque `if __name__ == "__main__"` para testing independiente:

```bash
# Test individual de cada m√≥dulo
python market_data_cache_v5.py
python logging_config_v5.py
python ml_model_v5.py
python optimizer_v5.py
python alternative_data_v5.py
python divergence_detector_v5.py
python backtester_v5.py
```

---

## üì¶ Estructura de Archivos

```
v4/
‚îú‚îÄ‚îÄ penny_stock_advisor_v4.py         # Base V4 (existente)
‚îú‚îÄ‚îÄ integration_v4_trading_manager.py # Base V4 (existente)
‚îú‚îÄ‚îÄ penny_stock_advisor_v5.py         # NUEVO - A crear
‚îú‚îÄ‚îÄ integration_v5_trading_manager.py # NUEVO - A crear
‚îú‚îÄ‚îÄ market_data_cache_v5.py           # ‚úÖ Completado
‚îú‚îÄ‚îÄ logging_config_v5.py              # ‚úÖ Completado
‚îú‚îÄ‚îÄ backtester_v5.py                  # ‚úÖ Completado
‚îú‚îÄ‚îÄ ml_model_v5.py                    # ‚úÖ Completado
‚îú‚îÄ‚îÄ optimizer_v5.py                   # ‚úÖ Completado
‚îú‚îÄ‚îÄ alternative_data_v5.py            # ‚úÖ Completado
‚îú‚îÄ‚îÄ divergence_detector_v5.py         # ‚úÖ Completado
‚îú‚îÄ‚îÄ cache/                            # Cach√© persistente
‚îú‚îÄ‚îÄ logs/                             # Archivos de log
‚îú‚îÄ‚îÄ models/                           # Modelos ML
‚îî‚îÄ‚îÄ data/                             # Datos alternativos (CSV)
```

---

## üéØ Pr√≥ximos Pasos

1. ‚úÖ Crear archivos de m√≥dulos auxiliares (COMPLETADO)
2. ‚è≥ Crear `penny_stock_advisor_v5.py` integrando todos los m√≥dulos
3. ‚è≥ Crear `integration_v5_trading_manager.py` con nuevo flujo
4. ‚è≥ Preparar dataset de entrenamiento para ML
5. ‚è≥ Testing completo del sistema V5
6. ‚è≥ Documentaci√≥n de uso

---

## üíæ Dataset de Entrenamiento Esperado

Crear `training_data.csv` con este formato:

```csv
symbol,date,bb_width,adx,vol_ratio,rsi,macd_diff,atr_ratio,short_float,compression_days,volume_dry,price_range_pct,exploded
BYND,2024-05-15,0.08,18.3,2.9,62,0.003,0.015,0.12,7,1,6.5,1
COSM,2024-05-18,0.10,22.1,1.7,48,-0.002,0.025,0.09,5,0,8.2,0
...
```

- **exploded**: 1 si el setup result√≥ en breakout real, 0 si no

---

## üìö Referencias

- **Logging**: [Python logging.config](https://docs.python.org/3/library/logging.config.html)
- **LRU Cache**: [functools.lru_cache](https://docs.python.org/3/library/functools.html#functools.lru_cache)
- **Random Forest**: [sklearn.RandomForestClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html)
- **ThreadPoolExecutor**: [concurrent.futures](https://docs.python.org/3/library/concurrent.futures.html)

---

Generated by Claude Code - V5 Upgrade Project
Date: 2025-10-24
