# Fuzzy Matching V5 - 100% GPU

## ğŸš€ Cambio Principal: Fuzzy en GPU

### Antes (V4) - Cuello de botella CPU
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  EMBEDDINGS        â†’  GPU  âœ“  RÃ¡pido                    â”‚
â”‚  SEMANTIC SCORE    â†’  GPU  âœ“  RÃ¡pido                    â”‚
â”‚  FUZZY (RapidFuzz) â†’  CPU  âœ—  LENTO (ProcessPool)       â”‚
â”‚  I/O               â†’  Disco                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Ahora (V5) - Todo en GPU
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  EMBEDDINGS        â†’  GPU  âœ“  RÃ¡pido                    â”‚
â”‚  SEMANTIC SCORE    â†’  GPU  âœ“  RÃ¡pido                    â”‚
â”‚  FUZZY (N-gramas)  â†’  GPU  âœ“  Â¡RÃPIDO!                  â”‚
â”‚  I/O               â†’  Disco                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“ CÃ³mo funciona el Fuzzy GPU

### AnalogÃ­a: Huellas Digitales de Texto

Imagina que cada nombre es una huella digital compuesta de "fragmentos" (trigramas):

```
"John Smith" â†’ {"joh", "ohn", "hn ", "n s", " sm", "smi", "mit", "ith"}
"Jon Smyth"  â†’ {"jon", "on ", "n s", " sm", "smy", "myt", "yth"}
```

**Similitud = fragmentos en comÃºn / fragmentos totales**

Esto es **Jaccard Similarity**, y es PERFECTA para GPU porque:
- Se puede representar como vectores binarios
- Las operaciones son `min()`, `max()`, `sum()` - altamente paralelas
- No hay bucles dependientes como en Levenshtein

### Paso a Paso

1. **Preprocesamiento**
   ```
   "John Smith LLC" â†’ "john smith" â†’ tokens ordenados â†’ "john smith"
   ```

2. **ExtracciÃ³n de trigramas**
   ```
   "john smith" â†’ {"joh", "ohn", "hn ", "n s", " sm", "smi", "mit", "ith"}
   ```

3. **Feature Hashing** (vector de tamaÃ±o fijo)
   ```
   Cada trigrama â†’ hash() % 4096 â†’ Ã­ndice en vector
   Vector resultante: [0,0,1,0,0,1,0,0,1,0,0,1,...] (4096 dims)
   ```

4. **Jaccard en GPU** (vectorizado)
   ```python
   intersection = torch.minimum(vec_a, vec_b).sum()
   union = torch.maximum(vec_a, vec_b).sum()
   similarity = intersection / union
   ```

---

## âš¡ Rendimiento Esperado

| MÃ©trica | V4 (CPU Fuzzy) | V5 (GPU Fuzzy) | Speedup |
|---------|----------------|----------------|---------|
| RTX 3060 Ti | ~20K filas/s | ~60-80K filas/s | **3-4x** |
| RTX 5070 Ti | ~25K filas/s | ~120-150K filas/s | **5-6x** |
| Mac M4 Pro | ~15K filas/s | ~40-50K filas/s | **3x** |

### Para tus 166M filas:

| VersiÃ³n | Tiempo Estimado |
|---------|-----------------|
| V4 (actual) | ~2h 20min |
| V5 (RTX 3060 Ti) | ~45min - 1h |
| V5 (RTX 5070 Ti) | ~25-35min |

---

## ğŸ“Š CorrelaciÃ³n con RapidFuzz

Jaccard de trigramas NO es idÃ©ntico a `token_sort_ratio`, pero estÃ¡ altamente correlacionado:

| MÃ©trica | CorrelaciÃ³n |
|---------|-------------|
| Jaccard 3-gram vs token_sort_ratio | ~0.85-0.92 |
| Jaccard 2-gram vs token_sort_ratio | ~0.78-0.85 |
| Jaccard 4-gram vs token_sort_ratio | ~0.82-0.88 |

**Para fuzzy matching de nombres, trigramas (n=3) dan el mejor balance.**

---

## ğŸ› ï¸ Uso

### InstalaciÃ³n (misma que V4)
```bash
pip install polars sentence-transformers torch tqdm rich
```

### EjecuciÃ³n
```bash
# Primera ejecuciÃ³n
python fuzzy_match_v5_full_gpu.py \
  --input resultados_matching/matched_DE.parquet \
  --output resultados_matching/DE_v5/

# Continuar si se interrumpe
python fuzzy_match_v5_full_gpu.py \
  --resume \
  --input resultados_matching/matched_DE.parquet \
  --output resultados_matching/DE_v5/
```

### ParÃ¡metros de n-gramas
```bash
# Ajustar precisiÃ³n vs velocidad
--ngram-size 3    # Default: trigramas (mejor para nombres)
--hash-dim 4096   # Default: dimensiÃ³n del vector hash
                  # MÃ¡s alto = mÃ¡s preciso pero mÃ¡s memoria
                  # 4096 es un buen balance
```

---

## ğŸ”§ Ajustes de Rendimiento

### Si tienes MUCHA VRAM (16GB+)
```bash
--hash-dim 8192 --batch-size 100000
```

### Si tienes POCA VRAM (8GB)
```bash
--hash-dim 2048 --batch-size 30000
```

### Si quieres mÃ¡xima precisiÃ³n (mÃ¡s lento)
```bash
--hash-dim 16384 --ngram-size 2
```

---

## ğŸ“ Estructura de Archivos

```
resultados_matching/DE_v5/
â”œâ”€â”€ matched_matched_DE_fuzzy_v5_gpu.parquet
â”œâ”€â”€ matched_matched_DE_fuzzy_v5_gpu_high_confidence.parquet
â”œâ”€â”€ cache_embeddings/
â”‚   â”œâ”€â”€ embeddings_all-MiniLM-L6-v2.pkl
â”‚   â””â”€â”€ ngram_vectors_3_4096.pkl    # â† Nuevo cache de n-gramas
â”œâ”€â”€ checkpoints_v5/                  # â† Checkpoints separados de V4
â”‚   â”œâ”€â”€ checkpoint.json
â”‚   â””â”€â”€ partitions/
â””â”€â”€ fuzzy_match_gpu_*.log
```

---

## âš ï¸ Notas Importantes

1. **Checkpoints separados**: V5 usa `checkpoints_v5/`, no interfiere con V4

2. **Cache de n-gramas**: Se guarda para futuras ejecuciones, igual que embeddings

3. **Compatibilidad de resultados**: Los scores de V5 no son idÃ©nticos a V4, pero el ranking es similar. Si necesitas comparar exactamente con resultados anteriores, usa V4.

4. **Primera ejecuciÃ³n**: MÃ¡s lenta porque calcula todos los vectores n-grama. Las siguientes usan cache.

---

## ğŸ†š Â¿CuÃ¡ndo usar V4 vs V5?

| SituaciÃ³n | RecomendaciÃ³n |
|-----------|---------------|
| Procesamiento rÃ¡pido de grandes volÃºmenes | **V5** |
| Necesitas reproducir exactamente RapidFuzz | V4 |
| Mac con MPS | **V5** (mejor aprovechamiento) |
| CPU solamente | V4 (V5 funciona pero sin ventaja) |
| Primera vez probando | V4 (mÃ¡s estÃ¡ndar) |
| Ya validaste con V4 y quieres escalar | **V5** |
